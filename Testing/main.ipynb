{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f845585f-c0ab-4400-bca7-eced13331fcd",
   "metadata": {},
   "source": [
    "# Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c63fcf14-8bc0-4807-9b95-1d75b345c6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yaspin in c:\\users\\andrew\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (2.5.0)\n",
      "Requirement already satisfied: termcolor<3.0,>=2.3 in c:\\users\\andrew\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from yaspin) (2.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: C:\\Users\\Andrew\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install yaspin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71945bb2-a390-4016-9533-c9bbcdc72564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# static path variables\n",
    "paths = {\n",
    "    \"ASSIST09\" : \"data/ASSISTments2009/\",\n",
    "    \"NEUR20\" : \"data/NeurIPS2020/\",\n",
    "}\n",
    "wranglers = {\n",
    "    \"ASSIST09\" : \"data/ASSISTments2009/assistments09_wrangler\", \n",
    "    \"NEUR20\" : \"data/NeurIPS2020/neurIPS2020_wrangler\",\n",
    "}\n",
    "models = { #might not need this\n",
    "    \"IRT\" : \"models/IRT/IRT\",\n",
    "}\n",
    "prepper_path = \"data/dataPrepper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e05eb094-1f93-4528-ba69-74d9688035f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def checkExists(path):\n",
    "    #remove the .py file if it exists\n",
    "    if(os.path.exists(path)):\n",
    "        print(\"found \" + path)\n",
    "        return True\n",
    "    else:\n",
    "        print(\"couldn't find \" + path)\n",
    "        print(f\"Try running: !jupyter nbconvert --to script {path[:-2] + 'ipynb'}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4ffc54f-9820-4d95-aca4-2d434ff08923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found data/dataPrepper.py\n",
      "found models/IRT/IRT.py\n",
      "found data/ASSISTments2009/assistments09_wrangler.py\n",
      "found data/NeurIPS2020/neurIPS2020_wrangler.py\n"
     ]
    }
   ],
   "source": [
    "# A temporary measure while working in notebooks\n",
    "# Ensure all necesary scripts have been converted from notebooks\n",
    "allExists = True\n",
    "\n",
    "allExists = checkExists(prepper_path + \".py\") and allExists\n",
    "\n",
    "for key in models.keys():\n",
    "    allExists = checkExists(models[key] + \".py\") and allExists\n",
    "\n",
    "for key in wranglers.keys():\n",
    "    allExists = checkExists(wranglers[key] + \".py\") and allExists\n",
    "\n",
    "if(not allExists):\n",
    "    print(\"\\nMissing critical .py file(s), see above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a52eeae8-0519-4ff3-8335-0e963c11383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter nbconvert --to script data/dataPrepper.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f83579f0-09cb-4402-a446-50f222c5935a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select a model to test:\n",
      "1.IRT\n",
      " 1\n",
      "Select a dataset to test on:\n",
      "1.ASSIST09\n",
      "2.NEUR20\n",
      " 2\n",
      "Select a run condition:\n",
      "1.basic\n",
      "2.sampled\n",
      "3.correctSaturated\n",
      "4.incorrectSaturated\n",
      " 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing test run of IRT using NEUR20 in basic format\n"
     ]
    }
   ],
   "source": [
    "modelList ={\n",
    "    \"1\":\"IRT\",\n",
    "}\n",
    "\n",
    "datasetList = {\n",
    "    \"1\":\"ASSIST09\",\n",
    "    \"2\":\"NEUR20\",\n",
    "}\n",
    "\n",
    "runTypeList = {\n",
    "    \"1\":\"basic\",\n",
    "    \"2\":\"sampled\",\n",
    "    \"3\":\"correctSaturated\",\n",
    "    \"4\":\"incorrectSaturated\",\n",
    "}\n",
    "\n",
    "model = modelList[input(f\"Select a model to test:\\n\" + \"\\n\".join([f'{k}.{modelList[k]}' for k in modelList.keys()]) + \"\\n\")]\n",
    "dataset = datasetList[input(f\"Select a dataset to test on:\\n\" + \"\\n\".join([f'{k}.{datasetList[k]}' for k in datasetList.keys()]) + \"\\n\")]\n",
    "runType = runTypeList[input(f\"Select a run condition:\\n\" + \"\\n\".join([f'{k}.{runTypeList[k]}' for k in runTypeList.keys()]) + \"\\n\")]\n",
    "\n",
    "print(f\"Performing test run of {model} using {dataset} in {runType} format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76b7c878-bb5d-408b-9a93-aaab784e8548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building a response matrix...\n",
      "Created a response matrix for 118971 users and 27613 problems with 15867850 responses\n",
      "Using Existing Q matrix\n",
      "Using Existing response matrix\n",
      "NeurIPS202 wrangling complete!\n",
      "⠋ Preparing Data...preparing data from NEUR20 to train IRT for basic format\n",
      "✔️  Preparing Data...\n"
     ]
    }
   ],
   "source": [
    "from data import dataPrepper as prep\n",
    "from yaspin import yaspin\n",
    "from models.IRT import IRT\n",
    "\n",
    "with yaspin(text=\"Preparing Data...\") as spinner:\n",
    "    Q, data = prep.prepareData(dataset = dataset, runType = runType, model = model)\n",
    "    spinner.ok(\"✔️ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "953f0180-076d-43ae-8dcd-6330da8a2fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!SAVE DATA VARIABLE TO CSV, takes FOREVER!\n",
    "for x in range(len(data)):\n",
    "    data[x][\"train\"].to_csv(\"prepared_NEUR20_train_\" + str(x) + \".csv\")\n",
    "    data[x][\"test\"].to_csv(\"prepared_NEUR20_test_\" + str(x) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c197f79d-0efe-45a5-9635-1619b0b8e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFuncs = {\n",
    "    \"IRT\": IRT.run_IRT,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ecd7f38-37b0-4f87-93ca-f801b51e4b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                \r"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 24.5 GiB for an array with shape (118971, 27613) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m     26\u001b[0m     start_timer \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 27\u001b[0m     acc, auc, mae, rmse \u001b[38;5;241m=\u001b[39m \u001b[43mmodelFuncs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     end_timer \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     30\u001b[0m     accs\u001b[38;5;241m.\u001b[39mappend(acc)\n",
      "File \u001b[1;32m~\\Documents\\AJT WKU\\Thesis\\Graduate_Thesis\\Testing\\models\\IRT\\IRT.py:215\u001b[0m, in \u001b[0;36mrun_IRT\u001b[1;34m(train_data, test_data)\u001b[0m\n\u001b[0;32m    212\u001b[0m stu_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mmax\u001b[39m(train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mmax\u001b[39m(test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m    213\u001b[0m prob_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mmax\u001b[39m(train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mmax\u001b[39m(test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m--> 215\u001b[0m R \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstu_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprob_num\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m R[train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m#R matrix shows each question a student answered and whether they got it correct or incorrect\u001b[39;00m\n\u001b[0;32m    218\u001b[0m test_set \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 24.5 GiB for an array with shape (118971, 27613) and data type float64"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#find average training correct/incorrect ratio per student (should be ~0.50)\n",
    "avg_train_score = []\n",
    "avg_test_score = []\n",
    "for d in data:\n",
    "    avg_train_score.append(d[\"train\"].groupby('user_id')[\"score\"].mean().mean())\n",
    "    avg_test_score.append(d[\"test\"].groupby('user_id')[\"score\"].mean().mean())\n",
    "\n",
    "result_object = {\n",
    "    \"model\" : model,\n",
    "    \"runType\" : runType,\n",
    "    \"dataset\" : dataset,\n",
    "    \"test_correct_ratio\":np.mean(avg_test_score),\n",
    "    \"train_correct_ratio\":np.mean(avg_train_score),\n",
    "}\n",
    "\n",
    "accs, aucs, maes, rmses, times = [], [], [], [], []\n",
    "\n",
    "#run each provided data configuration and collect statistics\n",
    "with yaspin(text=\"Evaluating...\") as spinner:\n",
    "    for run in data:\n",
    "        start_timer = time.time()\n",
    "        acc, auc, mae, rmse = modelFuncs[model](run[\"train\"], run[\"test\"])\n",
    "        end_timer = time.time()\n",
    "        \n",
    "        accs.append(acc)\n",
    "        aucs.append(auc)\n",
    "        maes.append(mae)\n",
    "        rmses.append(rmse)\n",
    "        times.append(end_timer - start_timer)\n",
    "    spinner.ok(\"✔️ \")\n",
    "\n",
    "#format the output\n",
    "result_object['ACC'] = np.mean(accs)\n",
    "result_object['AUC'] = np.mean(aucs)\n",
    "result_object['MAE'] = np.mean(maes)\n",
    "result_object['RMSE'] = np.mean(rmses)\n",
    "result_object['ACC_std'] = np.std(accs)\n",
    "result_object['AUC_std'] = np.std(aucs)\n",
    "result_object['MAE_std'] = np.std(maes)\n",
    "result_object['RMSE_std'] = np.std(rmses)\n",
    "result_object['avg_train_duration'] = np.mean(times)\n",
    "result_object['performed_at'] = datetime.today().strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0847fd5-d88a-4948-b9ed-a9bfa0c9ec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#print the output to a csv\n",
    "results_path = \"results.csv\"\n",
    "\n",
    "#if the csv doesn't exist create it\n",
    "if not os.path.exists(results_path):\n",
    "    df = pd.DataFrame([result_object])\n",
    "else:\n",
    "    #pull in the csv as a dataframe\n",
    "    df = pd.read_csv(results_path)\n",
    "    #remove any existing row that has the same...\n",
    "        #model, runtype, and dataset\n",
    "    df = df[~((df['model'] == model) & (df['runType'] == runType) & (df['dataset'] == dataset))]\n",
    "    #add the new row\n",
    "    df = pd.concat([df, pd.DataFrame(result_object, index=[1])], ignore_index=True)\n",
    "df.to_csv(results_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89506368-83bb-42c7-a7ac-e301004464c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
