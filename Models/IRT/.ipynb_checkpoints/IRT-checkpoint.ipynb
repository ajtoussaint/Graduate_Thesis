{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daa6cc71-236f-4a9a-84b7-dc9523f4402c",
   "metadata": {},
   "source": [
    "# Package Links\n",
    "EduData: https://pypi.org/project/EduData/ EduCDM: https://pypi.org/project/EduCDM/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca247c4d-6cae-480a-9bf7-7aef4e8e87b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip --quiet install EduData\n",
    "!pip --quiet install EduCDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb95c07-3006-4d00-990b-d93d58d53c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use package for easy download of files\n",
    "from EduData import get_data\n",
    "get_data(\"cdbd-a0910\", \"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea6c8ab-caef-435f-9180-d6d02885c91f",
   "metadata": {},
   "source": [
    "This code is heavily based on Edu CDM:</br>\n",
    "@misc{bigdata2021educdm,\n",
    "  title={EduCDM},\n",
    "  author={bigdata-ustc},\n",
    "  publisher = {GitHub},\n",
    "  journal = {GitHub repository},\n",
    "  year = {2021},\n",
    "  howpublished = {\\url{https://github.com/bigdata-ustc/EduCDM}},\n",
    "}<br></br>\n",
    "Specifically the 3 parameter logistic IRT Model as presented in *Reckase, Mark D. \"18 Multidimensional Item Response Theory.\" _Handbook of statistics_ 26 (2006): 607-642.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2ca596-b1c5-41b8-8072-c8c9ebe44741",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd6f6501-7acd-405a-925b-82a2c1a9f16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1615</td>\n",
       "      <td>12977</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>782</td>\n",
       "      <td>13124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1084</td>\n",
       "      <td>16475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>8690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127</td>\n",
       "      <td>14225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  score\n",
       "0     1615    12977      1\n",
       "1      782    13124      0\n",
       "2     1084    16475      0\n",
       "3      593     8690      0\n",
       "4      127    14225      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from files\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"../data/a0910/train.csv\")\n",
    "valid_data = pd.read_csv(\"../data/a0910/valid.csv\")\n",
    "test_data = pd.read_csv(\"../data/a0910/test.csv\")\n",
    "\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd5f0712-ce74-4521-80e1-0f1ac31c6a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186049, 25606, 55760)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(valid_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "025a266b-e0c6-400d-9352-12f03c6433ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4128 17746\n"
     ]
    }
   ],
   "source": [
    "stu_num = max(max(train_data['user_id']), max(test_data['user_id']))\n",
    "prob_num = max(max(train_data['item_id']), max(test_data['item_id']))\n",
    "print(stu_num, prob_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b12621b2-910a-4fa4-8884-0529fe9e94b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "R = -1 * np.ones(shape=(stu_num, prob_num))\n",
    "R[train_data['user_id']-1, train_data['item_id']-1] = train_data['score'] #R matrix shows each question a student answered and whether they got it correct or incorrect\n",
    "\n",
    "test_set = []\n",
    "for i in range(len(test_data)):\n",
    "    row = test_data.iloc[i]\n",
    "    test_set.append({'user_id':int(row['user_id'])-1, 'item_id':int(row['item_id'])-1, 'score':row['score']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafaf6af-ab2d-4490-b4a7-3422ffcc699b",
   "metadata": {},
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaa01b86-43da-459c-92c6-8a119fe34bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d91683a-91fa-49e8-9555-d0482f97188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRT Required imports\n",
    "import logging\n",
    "import numpy as np\n",
    "import pickle #used to save and load parameter settings\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "#added to generate more metrics\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2847c6f0-eaac-4afd-9807-58f1e2daab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def irt3pl(theta, a, b, c, D=1.702, *, F=np): #compute probability of correct response\n",
    "    return c + (1 - c) / (1 + F.exp(-D * a * (theta - b))) #This equation dose NOT match the one in Reckase 06, not sure why\n",
    "    #theta: ability parameter of student\n",
    "    # a, b, c are as defined for init_parameters\n",
    "    # D is a scaling constant applied which causes the model to produce similar item characteristic curves to the normal ogive model\n",
    "    #NOTE: whenever this function is called theta is given as \"a * (theta - b)\" and a is given as 1 and b as 0 which is the same as actually plugging in the values. Not sure why this was done\n",
    "    #also the variable stu_prof is theta \n",
    "    \n",
    "#from EduCDM import CDM\n",
    "class CDM(object):\n",
    "    def __init__(self, *args, **kwargs) -> ...:\n",
    "        pass\n",
    "\n",
    "    def train(self, *args, **kwargs) -> ...:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def eval(self, *args, **kwargs) -> ...:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def save(self, *args, **kwargs) -> ...:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def load(self, *args, **kwargs) -> ...:\n",
    "        raise NotImplementedError\n",
    "\n",
    "def init_parameters(prob_num, dim): # Initializes distributions to be refined\n",
    "    alpha = stats.norm.rvs(loc=0.75, scale=0.01, size=(prob_num, dim)) #alpha represents the \"differentiability\" of a given problem\n",
    "    beta = stats.norm.rvs(size=(prob_num, dim)) #beta represents the \"difficulty\" of a given problem\n",
    "    gamma = stats.uniform.rvs(size=prob_num) #gamma is the \"guess\" parameter associated with a problem\n",
    "    return alpha, beta, gamma\n",
    "\n",
    "\n",
    "def init_prior_prof_distribution(dim):\n",
    "    prof = stats.uniform.rvs(loc=-4, scale=8, size=(100, dim))  # shape = (100,dim) #generates a random 100xdim matrix with possible values -4 to 4\n",
    "    dis = stats.multivariate_normal.pdf(prof, mean=np.zeros(dim), cov=np.identity(dim)) # calculates probability density function\n",
    "    norm_dis = dis / np.sum(dis)  # shape = (100,) # normalizes density function\n",
    "    return prof, norm_dis\n",
    "\n",
    "\n",
    "def get_Likelihood(a, b, c, prof, R):\n",
    "    stu_num, prob_num = R.shape[0], R.shape[1]\n",
    "    prof_prob = irt3pl(np.sum(a * (np.expand_dims(prof, axis=1) - b), axis=-1), 1, 0, c)  # shape = (100, prob_num) #probability of correct response for each student item pair\n",
    "    tmp1, tmp2 = np.zeros(shape=(prob_num, stu_num)), np.zeros(shape=(prob_num, stu_num))\n",
    "    tmp1[np.where(R == 1)[1], np.where(R == 1)[0]] = 1\n",
    "    tmp2[np.where(R == 0)[1], np.where(R == 0)[0]] = 1\n",
    "    prob_stu = np.exp(np.dot(np.log(prof_prob + 1e-9), tmp1) + np.dot(np.log(1 - prof_prob + 1e-9), tmp2)) #likelihood of the actual observed responses\n",
    "    return prof_prob, prob_stu\n",
    "\n",
    "\n",
    "def update_prior(prior_dis, prof_stu_like): #update the given prior distribution based on the given likelihoods\n",
    "    dis_like = prof_stu_like * np.expand_dims(prior_dis, axis=1)\n",
    "    norm_dis_like = dis_like / np.sum(dis_like, axis=0)\n",
    "    update_prior_dis = np.sum(norm_dis_like, axis=1) / np.sum(norm_dis_like)\n",
    "    return update_prior_dis, norm_dis_like\n",
    "\n",
    "\n",
    "def update_irt(a, b, c, D, prof, R, r_ek, s_ek, lr, epoch=10, epsilon=1e-3): #updates the a, b, and c parameters of the model\n",
    "    for iteration in range(epoch):\n",
    "        a_tmp, b_tmp, c_tmp = np.copy(a), np.copy(b), np.copy(c)\n",
    "        prof_prob, _ = get_Likelihood(a, b, c, prof, R) #returns the probability of a correct response for each student/item pair\n",
    "        common_term = (r_ek - s_ek * prof_prob) / prof_prob / (1 - c + 1e-9)  # shape = (100, prob_num)\n",
    "        a_1 = np.transpose(\n",
    "            D * common_term * (prof_prob - c) * np.transpose(np.expand_dims(prof, axis=1) - b, (2, 0, 1)), (1, 2, 0))\n",
    "        b_1 = D * common_term * (c - prof_prob)\n",
    "        a_grad = np.sum(a_1, axis=0)\n",
    "        b_grad = a * np.expand_dims(np.sum(b_1, axis=0), axis=1)\n",
    "        c_grad = np.sum(common_term, axis=0)\n",
    "        a = a + lr * a_grad #increase each parameter along their gradient according to the learning rate\n",
    "        b = b + lr * b_grad\n",
    "        c = np.clip(c + lr * c_grad, 0, 1)\n",
    "        change = max(np.max(np.abs(a - a_tmp)), np.max(np.abs(b - b_tmp)), np.max(np.abs(c - c_tmp)))\n",
    "        if iteration > 5 and change < epsilon: #stop if 5 epochs have passed with no significant change\n",
    "            break\n",
    "    return a, b, c\n",
    "\n",
    "\n",
    "class IRT(CDM):\n",
    "    \"\"\"\n",
    "    IRT model, training (EM) and testing methods\n",
    "    Parameters\n",
    "    ----------\n",
    "    R: numpy.array\n",
    "        response matrix, shape = (stu_num, prob_num)\n",
    "    stu_num: int\n",
    "        number of students\n",
    "    prob_num: int\n",
    "        number of problems\n",
    "    dim: int\n",
    "        dimension of student/problem embedding, MIRT for dim > 1\n",
    "    skip_value: int\n",
    "        skip value in response matrix\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, R, stu_num, prob_num, dim=1, skip_value=-1):\n",
    "        super(IRT, self).__init__()\n",
    "        self.R, self.skip_value = R, skip_value\n",
    "        self.stu_num, self.prob_num, self.dim = stu_num, prob_num, dim\n",
    "        self.a, self.b, self.c = init_parameters(prob_num, dim)  # IRT parameters\n",
    "        self.D = 1.702\n",
    "        self.prof, self.prior_dis = init_prior_prof_distribution(dim) #start with random proabaility of correct response and normalized density\n",
    "        self.stu_prof = np.zeros(shape=(stu_num, dim))\n",
    "\n",
    "    def train(self, lr, epoch, epoch_m=10, epsilon=1e-3):\n",
    "        a, b, c = np.copy(self.a), np.copy(self.b), np.copy(self.c)\n",
    "        prior_dis = np.copy(self.prior_dis)\n",
    "        for iteration in range(epoch):\n",
    "            a_tmp, b_tmp, c_tmp, prior_dis_tmp = np.copy(a), np.copy(b), np.copy(c), np.copy(prior_dis)\n",
    "            prof_prob_like, prof_stu_like = get_Likelihood(a, b, c, self.prof, self.R) # returns the probability of a correct response and the likelihood of the observed response\n",
    "            prior_dis, norm_dis_like = update_prior(prior_dis, prof_stu_like) # based on the liklihood of the observed responses the prior distribution is updated\n",
    "\n",
    "            r_1 = np.zeros(shape=(self.stu_num, self.prob_num))\n",
    "            r_1[np.where(self.R == 1)[0], np.where(self.R == 1)[1]] = 1\n",
    "            r_ek = np.dot(norm_dis_like, r_1)  # shape = (100, prob_num)\n",
    "            r_1[np.where(self.R != self.skip_value)[0], np.where(self.R != self.skip_value)[1]] = 1\n",
    "            s_ek = np.dot(norm_dis_like, r_1)  # shape = (100, prob_num)\n",
    "            #the irt function parameters are updated based on information from the new normalized likelihood distribution\n",
    "            a, b, c = update_irt(a, b, c, self.D, self.prof, self.R, r_ek, s_ek, lr, epoch_m, epsilon) \n",
    "            change = max(np.max(np.abs(a - a_tmp)), np.max(np.abs(b - b_tmp)), np.max(np.abs(c - c_tmp)),\n",
    "                         np.max(np.abs(prior_dis_tmp - prior_dis_tmp)))\n",
    "            if iteration > 20 and change < epsilon: #stop iterating if the updated parameters have converged\n",
    "                break\n",
    "        self.a, self.b, self.c, self.prior_dis = a, b, c, prior_dis\n",
    "        self.stu_prof = self.transform(self.R) #applies MLE to update the student profiles\n",
    "\n",
    "    def eval(self, test_data) -> tuple:\n",
    "        pred_score = irt3pl(np.sum(self.a * (np.expand_dims(self.stu_prof, axis=1) - self.b), axis=-1), 1, 0, self.c)\n",
    "        test_rmse, test_mae, y_true, y_pred = [], [], [], [] # y matricies used to calculate AUC and ACC\n",
    "        for i in tqdm(test_data, \"evaluating\"):\n",
    "            stu, test_id, true_score = i['user_id'], i['item_id'], i['score']\n",
    "            test_rmse.append((pred_score[stu, test_id] - true_score) ** 2)\n",
    "            test_mae.append(abs(pred_score[stu, test_id] - true_score))\n",
    "\n",
    "            #for ACC and AUC\n",
    "            predicted = pred_score[stu, test_id]\n",
    "            y_true.append(true_score)\n",
    "            y_pred.append(predicted)\n",
    "\n",
    "        rmse = np.sqrt(np.average(test_rmse))\n",
    "        mae = np.average(test_mae)\n",
    "        accuracy = accuracy_score(y_true, [1 if p >= 0.5 else 0 for p in y_pred])\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        \n",
    "        return rmse, mae, accuracy, auc\n",
    "\n",
    "    def save(self, filepath):\n",
    "        with open(filepath, 'wb') as file:\n",
    "            pickle.dump({\"a\": self.a, \"b\": self.b, \"c\": self.c, \"prof\": self.stu_prof}, file)\n",
    "            logging.info(\"save parameters to %s\" % filepath)\n",
    "\n",
    "    def load(self, filepath):\n",
    "        with open(filepath, 'rb') as file:\n",
    "            self.a, self.b, self.c, self.stu_prof = pickle.load(file).values()\n",
    "            logging.info(\"load parameters from %s\" % filepath)\n",
    "\n",
    "    def inc_train(self, inc_train_data, lr=1e-3, epoch=10, epsilon=1e-3):  # incremental training, can be applied in real time as students generate responses\n",
    "        for i in inc_train_data:\n",
    "            stu, test_id, true_score = i['user_id'], i['item_id'], i['score']\n",
    "            self.R[stu, test_id] = true_score\n",
    "        self.train(lr, epoch, epsilon=epsilon)\n",
    "\n",
    "    def transform(self, records, lr=1e-3, epoch=10, epsilon=1e-3):  # MLE for evaluating students' state\n",
    "        # can evaluate multiple students' states simultaneously, thus output shape = (stu_num, dim)\n",
    "        # initialization stu_prof, shape = (stu_num, dim)\n",
    "        if len(records.shape) == 1:  # one student\n",
    "            records = np.expand_dims(records, axis=0)\n",
    "        _, prof_stu_like = get_Likelihood(self.a, self.b, self.c, self.prof, records)\n",
    "        stu_prof = self.prof[np.argmax(prof_stu_like, axis=0)]\n",
    "\n",
    "        for iteration in range(epoch):\n",
    "            prof_tmp = np.copy(stu_prof)\n",
    "            ans_prob = irt3pl(np.sum(self.a * (np.expand_dims(stu_prof, axis=1) - self.b), axis=-1), 1, 0, self.c)\n",
    "            ans_1 = self.D * (records - ans_prob) / ans_prob * (ans_prob - self.c) / (1 - self.c + 1e-9)\n",
    "            ans_1[np.where(records == self.skip_value)[0], np.where(records == self.skip_value)[1]] = 0\n",
    "            prof_grad = np.dot(ans_1, self.a)\n",
    "            stu_prof = stu_prof - lr * prof_grad\n",
    "            change = np.max(np.abs(stu_prof - prof_tmp))\n",
    "            if iteration > 5 and change < epsilon:\n",
    "                break\n",
    "        return stu_prof  # shape = (stu_num, dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a54cfffd-d4a0-4274-a3fe-cb5944cc2b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:save parameters to irt.params\n"
     ]
    }
   ],
   "source": [
    "#from EduCDM import EMIRT\n",
    "cdm = IRT(R, stu_num, prob_num, dim=1, skip_value=-1)\n",
    "\n",
    "cdm.train(lr=1e-3, epoch=2)\n",
    "cdm.save(\"irt.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54b9090f-f3eb-4047-a68a-c7462a7a7fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load parameters from irt.params\n",
      "evaluating: 100%|████████████████████████████████████████████████████████████| 55760/55760 [00:00<00:00, 713804.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.452013, MAE: 0.383786, ACC: 0.689437, AUC: 0.696707\n"
     ]
    }
   ],
   "source": [
    "cdm.load(\"irt.params\")\n",
    "rmse, mae, acc, auc = cdm.eval(test_set)\n",
    "print(\"RMSE: %.6f, MAE: %.6f, ACC: %.6f, AUC: %.6f\" % (rmse, mae, acc, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0063ba79-a445-40d4-86fd-6b11522758db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
