{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "820aec67-993a-46d2-b376-13c71f5bc9aa",
   "metadata": {},
   "source": [
    "This code is heavily based on Edu CDM:\n",
    "@misc{bigdata2021educdm, title={EduCDM}, author={bigdata-ustc}, publisher = {GitHub}, journal = {GitHub repository}, year = {2021}, howpublished = {\\url{https://github.com/bigdata-ustc/EduCDM}}, }\n",
    "\n",
    "Specifically the presentation of the MIRT model as proposed in Reckase, Mark D. \"18 Multidimensional Item Response Theory.\" _Handbook of statistics_ 26 (2006): 607-642."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc3c55c-6e2a-4ad8-9f84-3d8f32ccdc50",
   "metadata": {},
   "source": [
    "# Package Links\n",
    "EduData: https://pypi.org/project/EduData/ EduCDM: https://pypi.org/project/EduCDM/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca445b00-3480-453c-a1da-2312dce2d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip --quiet install EduData\n",
    "!pip --quiet install EduCDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf28f18-f3fd-4f46-9c24-0ce328b99d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloader, INFO http://base.ustc.edu.cn/data/cdbd/a0910/item.csv is saved as ..\\data\\a0910\\item.csv\n",
      "downloader, INFO file existed, skipped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'..\\\\data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use package for easy download of files\n",
    "from EduData import get_data\n",
    "get_data(\"cdbd-a0910\", \"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cd970a-eef2-4a13-b115-d48cdc3add24",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba023ef8-09a7-419b-8a9d-5f50bc074141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1615</td>\n",
       "      <td>12977</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>782</td>\n",
       "      <td>13124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1084</td>\n",
       "      <td>16475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>8690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127</td>\n",
       "      <td>14225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  score\n",
       "0     1615    12977      1\n",
       "1      782    13124      0\n",
       "2     1084    16475      0\n",
       "3      593     8690      0\n",
       "4      127    14225      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from files\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"../data/a0910/train.csv\")\n",
    "valid_data = pd.read_csv(\"../data/a0910/valid.csv\")\n",
    "test_data = pd.read_csv(\"../data/a0910/test.csv\")\n",
    "\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "131a46da-ec00-4c4f-b175-cfe08111eea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186049, 25606, 55760)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(valid_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8e1bf4b-86b7-426f-b5af-2b4b15029a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x2287caea520>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x2287caeaca0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x2287caf64c0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform data to torch Dataloader (i.e., batchify)\n",
    "# batch_size is set to 32\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 256\n",
    "def transform(x, y, z, batch_size, **params):\n",
    "    dataset = TensorDataset(\n",
    "        torch.tensor(x, dtype=torch.int64),\n",
    "        torch.tensor(y, dtype=torch.int64),\n",
    "        torch.tensor(z, dtype=torch.float)\n",
    "    )\n",
    "    return DataLoader(dataset, batch_size=batch_size, **params)\n",
    "\n",
    "train, valid, test = [\n",
    "    transform(data[\"user_id\"], data[\"item_id\"], data[\"score\"], batch_size)\n",
    "    for data in [train_data, valid_data, test_data]\n",
    "]\n",
    "train, valid, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecf570a-29a3-400b-89f5-5f13d5ebb4cf",
   "metadata": {},
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e98409a-7086-43b6-a606-dd3efea6ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "567b9696-d552-45dd-9a86-ebbb67b5cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "from EduCDM import CDM\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e8ed7a6-31d2-495e-a9f1-da811ff8d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from EduCDM import MIRT\n",
    "\n",
    "class CDM(object):\n",
    "    def __init__(self, *args, **kwargs) -> ...:\n",
    "        pass\n",
    "\n",
    "    def train(self, *args, **kwargs) -> ...:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def eval(self, *args, **kwargs) -> ...:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def save(self, *args, **kwargs) -> ...:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def load(self, *args, **kwargs) -> ...:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "def irt2pl(theta, a, b, c, *, F=np):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta\n",
    "    a\n",
    "    b\n",
    "    F\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> theta = [1, 0.5, 0.3]\n",
    "    >>> a = [-3, 1, 3]\n",
    "    >>> b = 0.5\n",
    "    >>> irt2pl(theta, a, b) # doctest: +ELLIPSIS\n",
    "    0.109...\n",
    "    >>> theta = [[1, 0.5, 0.3], [2, 1, 0]]\n",
    "    >>> a = [[-3, 1, 3], [-3, 1, 3]]\n",
    "    >>> b = [0.5, 0.5]\n",
    "    >>> irt2pl(theta, a, b) # doctest: +ELLIPSIS\n",
    "    array([0.109..., 0.004...])\n",
    "    \"\"\"\n",
    "    return c + (1 - c) / (1 + F.exp(- F.sum(F.multiply(a, theta), axis=-1) + b)) # Based on 2 parameter logistic model\n",
    "\n",
    "\n",
    "class MIRTNet(nn.Module):\n",
    "    def __init__(self, user_num, item_num, latent_dim, a_range, irf_kwargs=None):\n",
    "        super(MIRTNet, self).__init__()\n",
    "        self.user_num = user_num\n",
    "        self.item_num = item_num\n",
    "        self.irf_kwargs = irf_kwargs if irf_kwargs is not None else {}\n",
    "        self.theta = nn.Embedding(self.user_num, latent_dim)\n",
    "        self.a = nn.Embedding(self.item_num, latent_dim)\n",
    "        self.b = nn.Embedding(self.item_num, 1)\n",
    "        self.c = nn.Embedding(self.item_num, 1)\n",
    "        self.a_range = a_range\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        theta = torch.squeeze(self.theta(user), dim=-1) # theta, a, and b are extracted and squeezed to fit the appropriate dimensions\n",
    "        a = torch.squeeze(self.a(item), dim=-1)\n",
    "        if self.a_range is not None: #ensure a values are within the \"a_range\"\n",
    "            a = self.a_range * torch.sigmoid(a)\n",
    "        else:\n",
    "            a = F.softplus(a)\n",
    "        b = torch.squeeze(self.b(item), dim=-1)\n",
    "        c = torch.sigmoid(torch.squeeze(self.c(item), dim=-1)) #sigmoid activation keeps c in [0,1]\n",
    "        if torch.max(theta != theta) or torch.max(a != a) or torch.max(b != b):  # pragma: no cover # check for any NaN values\n",
    "            raise ValueError('ValueError:theta,a,b may contains nan!  The a_range is too large.')\n",
    "        return self.irf(theta, a, b, c,  **self.irf_kwargs) #compute output with irt2pl\n",
    "\n",
    "    @classmethod\n",
    "    def irf(cls, theta, a, b, c, **kwargs):\n",
    "        return irt2pl(theta, a, b, c, F=torch)\n",
    "\n",
    "\n",
    "class MIRT(CDM):\n",
    "    def __init__(self, user_num, item_num, latent_dim, a_range=None):\n",
    "        super(MIRT, self).__init__()\n",
    "        self.irt_net = MIRTNet(user_num, item_num, latent_dim, a_range)\n",
    "\n",
    "    def train(self, train_data, test_data=None, *, epoch: int, device=\"cpu\", lr=0.001) -> ...:\n",
    "        self.irt_net = self.irt_net.to(device)\n",
    "        loss_function = nn.BCELoss()\n",
    "\n",
    "        trainer = torch.optim.Adam(self.irt_net.parameters(), lr)\n",
    "\n",
    "        for e in range(epoch):\n",
    "            losses = []\n",
    "            for batch_data in tqdm(train_data, \"Epoch %s\" % e):\n",
    "                user_id, item_id, response = batch_data\n",
    "                user_id: torch.Tensor = user_id.to(device)\n",
    "                item_id: torch.Tensor = item_id.to(device)\n",
    "                predicted_response: torch.Tensor = self.irt_net(user_id, item_id)\n",
    "                response: torch.Tensor = response.to(device)\n",
    "                loss = loss_function(predicted_response, response)\n",
    "\n",
    "                # back propagation\n",
    "                trainer.zero_grad()\n",
    "                loss.backward()\n",
    "                trainer.step()\n",
    "\n",
    "                losses.append(loss.mean().item())\n",
    "            print(\"[Epoch %d] LogisticLoss: %.6f\" % (e, float(np.mean(losses))))\n",
    "\n",
    "            if test_data is not None:\n",
    "                auc, accuracy, rmse = self.eval(test_data, device=device)\n",
    "                print(\"[Epoch %d] auc: %.6f, accuracy: %.6f, rmse: %.6f\" % (e, auc, accuracy, rmse))\n",
    "\n",
    "    def eval(self, test_data, device=\"cpu\") -> tuple:\n",
    "        self.irt_net = self.irt_net.to(device)\n",
    "        self.irt_net.eval()\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for batch_data in tqdm(test_data, \"evaluating\"):\n",
    "            user_id, item_id, response = batch_data\n",
    "            user_id: torch.Tensor = user_id.to(device)\n",
    "            item_id: torch.Tensor = item_id.to(device)\n",
    "            pred: torch.Tensor = self.irt_net(user_id, item_id)\n",
    "            y_pred.extend(pred.tolist())\n",
    "            y_true.extend(response.tolist())\n",
    "\n",
    "        #calculate rmse\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        self.irt_net.train()\n",
    "        return roc_auc_score(y_true, y_pred), accuracy_score(y_true, np.array(y_pred) >= 0.5), rmse\n",
    "\n",
    "    def save(self, filepath):\n",
    "        torch.save(self.irt_net.state_dict(), filepath)\n",
    "        logging.info(\"save parameters to %s\" % filepath)\n",
    "\n",
    "    def load(self, filepath):\n",
    "        self.irt_net.load_state_dict(torch.load(filepath))\n",
    "        logging.info(\"load parameters from %s\" % filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12f3adde-d148-4709-8729-c580f50d7eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████████████████████████████████████████████████████████████████| 727/727 [00:04<00:00, 172.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] LogisticLoss: 4.740408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|███████████████████████████████████████████████████████████████████| 101/101 [00:00<00:00, 273.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] auc: 0.497733, accuracy: 0.573420, rmse: 0.559327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████████████████████████████████████████████████████████████████| 727/727 [00:03<00:00, 187.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] LogisticLoss: 1.925835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|███████████████████████████████████████████████████████████████████| 101/101 [00:00<00:00, 288.08it/s]\n",
      "INFO:root:save parameters to mirt.params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] auc: 0.497243, accuracy: 0.568968, rmse: 0.556275\n"
     ]
    }
   ],
   "source": [
    "cdm = MIRT(4164, 17747, 123)\n",
    "\n",
    "cdm.train(train, valid, epoch=2)\n",
    "cdm.save(\"mirt.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06f962a0-7151-4b98-aadd-24035df1858c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load parameters from mirt.params\n",
      "evaluating: 100%|███████████████████████████████████████████████████████████████████| 218/218 [00:00<00:00, 267.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.497638, accuracy: 0.567055, rmse: 0.559500\n"
     ]
    }
   ],
   "source": [
    "cdm.load(\"mirt.params\")\n",
    "auc, accuracy, rmse = cdm.eval(test)\n",
    "print(\"auc: %.6f, accuracy: %.6f, rmse: %.6f\" % (auc, accuracy, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f30202-a93f-4354-b9c2-6da38d8af9de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
