{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPcfZq9IHen6"
   },
   "source": [
    "This code is heavily based on Edu CDM:</br>\n",
    "@misc{bigdata2021educdm,\n",
    "  title={EduCDM},\n",
    "  author={bigdata-ustc},\n",
    "  publisher = {GitHub},\n",
    "  journal = {GitHub repository},\n",
    "  year = {2021},\n",
    "  howpublished = {\\url{https://github.com/bigdata-ustc/EduCDM}},\n",
    "}<br></br>\n",
    "Specifically the presentation of the NCDM model and example as originally proposed in: </br>\n",
    "@article{wang2022neuralcd,\n",
    "  title={NeuralCD: A General Framework for Cognitive Diagnosis},\n",
    "  author={Wang, Fei and Liu, Qi and Chen, Enhong and Huang, Zhenya and Yin, Yu and Wang, Shijin and Su, Yu},\n",
    "  journal={IEEE Transactions on Knowledge and Data Engineering},\n",
    "  year={2022},\n",
    "  publisher={IEEE}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSeolLzjIA1z"
   },
   "source": [
    "# Package Links\n",
    "EduData: https://pypi.org/project/EduData/\n",
    "EduCDM: https://pypi.org/project/EduCDM/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MrqZsbSFFY-q",
    "outputId": "a953df41-c744-43c4-b7d9-c166ceb28f31"
   },
   "outputs": [],
   "source": [
    "!pip --quiet install EduData\n",
    "!pip --quiet install EduCDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-96HqT72GKRq"
   },
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "HYHr0z4WFuh4",
    "outputId": "41e95b14-f007-4f6e-caf1-3717076bc6b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloader, INFO http://base.ustc.edu.cn/data/cdbd/a0910/item.csv is saved as ..\\data\\a0910\\item.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ..\\data\\a0910\\item.csv 100.00%: 252KB | 252KB"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloader, INFO http://base.ustc.edu.cn/data/cdbd/a0910/readme.txt is saved as ..\\data\\a0910\\readme.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading ..\\data\\a0910\\readme.txt 100.00%: 86.0B | 86.0B"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloader, INFO http://base.ustc.edu.cn/data/cdbd/a0910/test.csv is saved as ..\\data\\a0910\\test.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading ..\\data\\a0910\\test.csv 100.00%: 792KB | 792KB"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloader, INFO http://base.ustc.edu.cn/data/cdbd/a0910/train.csv is saved as ..\\data\\a0910\\train.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading ..\\data\\a0910\\train.csv 100.00%: 2.22MB | 2.22MB"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloader, INFO http://base.ustc.edu.cn/data/cdbd/a0910/valid.csv is saved as ..\\data\\a0910\\valid.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading ..\\data\\a0910\\valid.csv 100.00%: 363KB | 363KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'..\\\\data\\\\a0910'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use package for easy download of files\n",
    "from EduData import get_data\n",
    "get_data(\"cdbd-a0910\", \"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ualgRruJF_Rl",
    "outputId": "e5193ffb-f3dd-412f-fc97-32a0c792d826"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1615</td>\n",
       "      <td>12977</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>782</td>\n",
       "      <td>13124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1084</td>\n",
       "      <td>16475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>8690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127</td>\n",
       "      <td>14225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  score\n",
       "0     1615    12977      1\n",
       "1      782    13124      0\n",
       "2     1084    16475      0\n",
       "3      593     8690      0\n",
       "4      127    14225      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from files\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"../data/a0910/train.csv\")\n",
    "valid_data = pd.read_csv(\"../data/a0910/valid.csv\")\n",
    "test_data = pd.read_csv(\"../data/a0910/test.csv\")\n",
    "df_item = pd.read_csv(\"../data/a0910/item.csv\")\n",
    "item2knowledge = {}\n",
    "knowledge_set = set()\n",
    "for i, s in df_item.iterrows():\n",
    "    item_id, knowledge_codes = s['item_id'], list(set(eval(s['knowledge_code'])))\n",
    "    item2knowledge[item_id] = knowledge_codes\n",
    "    knowledge_set.update(knowledge_codes)\n",
    "\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yKKNZmnWGDK6",
    "outputId": "6901f04d-4a68-4018-e5e3-af81bb428a08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4128, 17746, 123)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get basic data info for model initialization\n",
    "import numpy as np\n",
    "user_n = np.max(train_data['user_id'])\n",
    "item_n = np.max([np.max(train_data['item_id']), np.max(valid_data['item_id']), np.max(test_data['item_id'])])\n",
    "knowledge_n = np.max(list(knowledge_set))\n",
    "\n",
    "user_n, item_n, knowledge_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e28RyJElGI8I",
    "outputId": "11074d61-2878-41c7-bddc-fb331eb01bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x16940f6e310>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1694107c850>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x16940ea8d30>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size is set to 32\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "def transform(user, item, item2knowledge, score, batch_size):\n",
    "    knowledge_emb = torch.zeros((len(item), knowledge_n))\n",
    "    for idx in range(len(item)):\n",
    "        knowledge_emb[idx][np.array(item2knowledge[item[idx]]) - 1] = 1.0\n",
    "\n",
    "    data_set = TensorDataset(\n",
    "        torch.tensor(user, dtype=torch.int64) - 1,  # (1, user_n) to (0, user_n-1)\n",
    "        torch.tensor(item, dtype=torch.int64) - 1,  # (1, item_n) to (0, item_n-1)\n",
    "        knowledge_emb,\n",
    "        torch.tensor(score, dtype=torch.float32)\n",
    "    )\n",
    "    return DataLoader(data_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "train_set, valid_set, test_set = [\n",
    "    transform(data[\"user_id\"], data[\"item_id\"], item2knowledge, data[\"score\"], batch_size)\n",
    "    for data in [train_data, valid_data, test_data]\n",
    "]\n",
    "\n",
    "train_set, valid_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVB8hrR4GtGs"
   },
   "source": [
    "# Building the NCDM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "NspeTjbmHXsn"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "WS-n5JS9KvSP"
   },
   "outputs": [],
   "source": [
    "#NCDM required imports\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "MiSpHW3tG64N"
   },
   "outputs": [],
   "source": [
    "# showing the NCDM class for understanding\n",
    "\n",
    "#from EduCDM import CDM\n",
    "class CDM(object):\n",
    "    def __init__(self, *args, **kwargs) -> ...:\n",
    "        pass\n",
    "\n",
    "    def train(self, *args, **kwargs) -> ...:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def eval(self, *args, **kwargs) -> ...:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def save(self, *args, **kwargs) -> ...:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def load(self, *args, **kwargs) -> ...:\n",
    "        raise NotImplementedError\n",
    "\n",
    "# from EduCDM import NCDM\n",
    "class PosLinear(nn.Linear):\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        weight = 2 * F.relu(1 * torch.neg(self.weight)) + self.weight\n",
    "        return F.linear(input, weight, self.bias)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, knowledge_n, exer_n, student_n):\n",
    "        self.knowledge_dim = knowledge_n\n",
    "        self.exer_n = exer_n\n",
    "        self.emb_num = student_n\n",
    "        self.stu_dim = self.knowledge_dim\n",
    "        self.prednet_input_len = self.knowledge_dim\n",
    "        self.prednet_len1, self.prednet_len2 = 512, 256  # changeable\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # prediction sub-net\n",
    "        self.student_emb = nn.Embedding(self.emb_num, self.stu_dim)\n",
    "        self.k_difficulty = nn.Embedding(self.exer_n, self.knowledge_dim)\n",
    "        self.e_difficulty = nn.Embedding(self.exer_n, 1)\n",
    "        self.prednet_full1 = PosLinear(self.prednet_input_len, self.prednet_len1)\n",
    "        self.drop_1 = nn.Dropout(p=0.5)\n",
    "        self.prednet_full2 = PosLinear(self.prednet_len1, self.prednet_len2)\n",
    "        self.drop_2 = nn.Dropout(p=0.5)\n",
    "        self.prednet_full3 = PosLinear(self.prednet_len2, 1)\n",
    "\n",
    "        # initialize\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.xavier_normal_(param)\n",
    "\n",
    "    def forward(self, stu_id, input_exercise, input_knowledge_point):\n",
    "        # before prednet\n",
    "        stu_emb = self.student_emb(stu_id)\n",
    "        stat_emb = torch.sigmoid(stu_emb)\n",
    "        k_difficulty = torch.sigmoid(self.k_difficulty(input_exercise))\n",
    "        e_difficulty = torch.sigmoid(self.e_difficulty(input_exercise))  # * 10\n",
    "        # prednet\n",
    "        input_x = e_difficulty * (stat_emb - k_difficulty) * input_knowledge_point\n",
    "        input_x = self.drop_1(torch.sigmoid(self.prednet_full1(input_x)))\n",
    "        input_x = self.drop_2(torch.sigmoid(self.prednet_full2(input_x)))\n",
    "        output_1 = torch.sigmoid(self.prednet_full3(input_x))\n",
    "\n",
    "        return output_1.view(-1)\n",
    "\n",
    "class NCDM(CDM):\n",
    "    '''Neural Cognitive Diagnosis Model'''\n",
    "\n",
    "    def __init__(self, knowledge_n, exer_n, student_n):\n",
    "        super(NCDM, self).__init__()\n",
    "        self.ncdm_net = Net(knowledge_n, exer_n, student_n)\n",
    "\n",
    "    def train(self, train_data, test_data=None, epoch=10, device=\"cpu\", lr=0.002, silence=False):\n",
    "        self.ncdm_net = self.ncdm_net.to(device)\n",
    "        self.ncdm_net.train()\n",
    "        loss_function = nn.BCELoss()\n",
    "        optimizer = optim.Adam(self.ncdm_net.parameters(), lr=lr)\n",
    "        for epoch_i in range(epoch):\n",
    "            epoch_losses = []\n",
    "            batch_count = 0\n",
    "            for batch_data in tqdm(train_data, \"Epoch %s\" % epoch_i):\n",
    "                batch_count += 1\n",
    "                user_id, item_id, knowledge_emb, y = batch_data\n",
    "                user_id: torch.Tensor = user_id.to(device)\n",
    "                item_id: torch.Tensor = item_id.to(device)\n",
    "                knowledge_emb: torch.Tensor = knowledge_emb.to(device)\n",
    "                y: torch.Tensor = y.to(device)\n",
    "                pred: torch.Tensor = self.ncdm_net(user_id, item_id, knowledge_emb)\n",
    "                loss = loss_function(pred, y)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_losses.append(loss.mean().item())\n",
    "\n",
    "            print(\"[Epoch %d] average loss: %.6f\" % (epoch_i, float(np.mean(epoch_losses))))\n",
    "\n",
    "            if test_data is not None:\n",
    "                auc, accuracy = self.eval(test_data, device=device)\n",
    "                print(\"[Epoch %d] auc: %.6f, accuracy: %.6f\" % (epoch_i, auc, accuracy))\n",
    "\n",
    "    def eval(self, test_data, device=\"cpu\"):\n",
    "        self.ncdm_net = self.ncdm_net.to(device)\n",
    "        self.ncdm_net.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        for batch_data in tqdm(test_data, \"Evaluating\"):\n",
    "            user_id, item_id, knowledge_emb, y = batch_data\n",
    "            user_id: torch.Tensor = user_id.to(device)\n",
    "            item_id: torch.Tensor = item_id.to(device)\n",
    "            knowledge_emb: torch.Tensor = knowledge_emb.to(device)\n",
    "            pred: torch.Tensor = self.ncdm_net(user_id, item_id, knowledge_emb)\n",
    "            y_pred.extend(pred.detach().cpu().tolist())\n",
    "            y_true.extend(y.tolist())\n",
    "\n",
    "        return roc_auc_score(y_true, y_pred), accuracy_score(y_true, np.array(y_pred) >= 0.5)\n",
    "\n",
    "    def save(self, filepath):\n",
    "        torch.save(self.ncdm_net.state_dict(), filepath)\n",
    "        logging.info(\"save parameters to %s\" % filepath)\n",
    "\n",
    "    def load(self, filepath):\n",
    "        self.ncdm_net.load_state_dict(torch.load(filepath))  # , map_location=lambda s, loc: s\n",
    "        logging.info(\"load parameters from %s\" % filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVeEk1sQLBRf"
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ky_iBnFK5Uz",
    "outputId": "435b0a96-bdf0-4b62-9f9b-8cd92cea22cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|█████████████████████████████████████████████████████████████████████| 5815/5815 [01:58<00:00, 49.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] average loss: 0.702545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████| 801/801 [00:01<00:00, 468.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] auc: 0.716589, accuracy: 0.681208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████████████████████████████████████████████| 5815/5815 [01:57<00:00, 49.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] average loss: 0.522655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████| 801/801 [00:01<00:00, 437.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] auc: 0.743691, accuracy: 0.726236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████████████████████████████| 5815/5815 [02:05<00:00, 46.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] average loss: 0.463883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████| 801/801 [00:01<00:00, 444.53it/s]\n",
      "INFO:root:save parameters to ncdm.snapshot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] auc: 0.750365, accuracy: 0.724713\n"
     ]
    }
   ],
   "source": [
    "device_str = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device_str = \"cuda\"\n",
    "\n",
    "cdm = NCDM(knowledge_n, item_n, user_n)\n",
    "cdm.train(train_set, valid_set, epoch=3, device=device_str)\n",
    "cdm.save(\"ncdm.snapshot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KePl_d59LC60"
   },
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8SX5KPkLLEhQ",
    "outputId": "ca901177-963f-4d87-e992-b258001f284f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load parameters from ncdm.snapshot\n",
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 1743/1743 [00:03<00:00, 460.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.752972, accuracy: 0.724444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cdm.load(\"ncdm.snapshot\")\n",
    "auc, accuracy = cdm.eval(test_set)\n",
    "print(\"auc: %.6f, accuracy: %.6f\" % (auc, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
